import os
import requests
import zipfile
import shutil
from tqdm import tqdm

# === 1. è®¾ç½®ä¸‹è½½é“¾æ¥ ===
# æ ¹æ®ä½ æä¾›çš„åœ°å€ï¼Œæ¨æµ‹æœ‰ä¸¤ä¸ªåˆ†å·æ–‡ä»¶ (.001 å’Œ .002)
DATASET_URLS = [
    "https://github.com/Norsico/yolodata/releases/download/0.1.0/SODA10M_82_10k.zip.001",
    "https://github.com/Norsico/yolodata/releases/download/0.1.0/SODA10M_82_10k.zip.002"
]

# === 2. è·¯å¾„é…ç½® ===
# åˆå¹¶åçš„å®Œæ•´å‹ç¼©åŒ…å­˜æ”¾è·¯å¾„
MERGED_ZIP_FILE = "/workspace/SODA10M_82_10k.zip"
# è§£å‹åçš„æ•°æ®é›†æ ¹ç›®å½•
DATASET_DIR = "/workspace/datasets/SODA10M_82_10k" 

def download_file(url, filename):
    """ä½¿ç”¨ requests + tqdm å®ç°å¸¦è¿›åº¦æ¡çš„ä¸‹è½½"""
    print(f"â¬‡ï¸ æ­£åœ¨ä¸‹è½½åˆ†å·: {os.path.basename(filename)}")
    response = requests.get(url, stream=True)
    total_size = int(response.headers.get('content-length', 0))
    block_size = 1024 * 1024 # 1 MB
    
    progress_bar = tqdm(total=total_size, unit='iB', unit_scale=True, desc=os.path.basename(filename))
    
    with open(filename, 'wb') as file:
        for data in response.iter_content(block_size):
            progress_bar.update(len(data))
            file.write(data)
    progress_bar.close()
    
    if total_size != 0 and progress_bar.n != total_size:
        print("âš ï¸ è­¦å‘Šï¼šä¸‹è½½å¯èƒ½ä¸å®Œæ•´")
    else:
        print("âœ… åˆ†å·ä¸‹è½½å®Œæˆ")

def merge_files(part_files, output_file):
    """å°†å¤šä¸ªåˆ†ç‰‡æ–‡ä»¶äºŒè¿›åˆ¶åˆå¹¶ä¸ºä¸€ä¸ªå¤§æ–‡ä»¶"""
    print(f"ğŸ”— æ­£åœ¨åˆå¹¶ {len(part_files)} ä¸ªåˆ†ç‰‡åˆ° {output_file} ...")
    
    with open(output_file, 'wb') as outfile:
        for part in part_files:
            print(f"   + è¯»å–åˆ†ç‰‡å¹¶å†™å…¥: {part}")
            with open(part, 'rb') as infile:
                shutil.copyfileobj(infile, outfile)
    
    print("âœ… åˆå¹¶å®Œæˆï¼")

def fix_nested_dir(target_dir):
    """
    æ£€æŸ¥æ˜¯å¦å­˜åœ¨åŒå±‚åµŒå¥— (ä¾‹å¦‚ target_dir/SODA10M_82_10k/images)ï¼Œ
    å¦‚æœå­˜åœ¨ï¼Œå°†å†…éƒ¨æ–‡ä»¶ç§»åŠ¨åˆ° target_dir å¹¶åˆ é™¤å¤šä½™å±‚çº§ã€‚
    """
    folder_name = os.path.basename(target_dir) # SODA10M_82_10k
    # çŒœæµ‹è§£å‹åå¯èƒ½å¤šäº†ä¸€å±‚åŒåæ–‡ä»¶å¤¹
    nested_path = os.path.join(target_dir, folder_name) 
    
    if os.path.exists(nested_path) and os.path.isdir(nested_path):
        print(f"âš ï¸ æ£€æµ‹åˆ°å¤šå±‚åµŒå¥—: {nested_path}")
        print("ğŸ”§ æ­£åœ¨ä¿®æ­£ç›®å½•ç»“æ„...")
        
        # ç§»åŠ¨æ–‡ä»¶
        for item in os.listdir(nested_path):
            src = os.path.join(nested_path, item)
            dst = os.path.join(target_dir, item)
            shutil.move(src, dst)
            
        # åˆ é™¤ç©ºæ–‡ä»¶å¤¹
        os.rmdir(nested_path)
        print("âœ… ç›®å½•ç»“æ„ä¿®æ­£å®Œæˆï¼")
    else:
        pass

# ================= ä¸»æµç¨‹ =================

if not os.path.exists(DATASET_DIR):
    # --- A. ä¸‹è½½ä¸åˆå¹¶é€»è¾‘ ---
    part_files = []
    
    # å¦‚æœè¿˜æ²¡æœ‰åˆå¹¶å¥½çš„å¤§åŒ…ï¼Œå°±å¼€å§‹ä¸‹è½½åˆ†å·
    if not os.path.exists(MERGED_ZIP_FILE):
        print("ğŸš€ å¼€å§‹å¤„ç†æ•°æ®é›†ä¸‹è½½ä»»åŠ¡...")
        
        # 1. ä¸‹è½½æ¯ä¸ªåˆ†å·
        for index, url in enumerate(DATASET_URLS):
            # ä¸´æ—¶æ–‡ä»¶åï¼Œä¾‹å¦‚ /workspace/SODA10M_82_10k.zip.001
            part_name = f"/workspace/temp_SODA_part_{index+1:03d}" 
            part_files.append(part_name)
            
            if not os.path.exists(part_name):
                download_file(url, part_name)
            else:
                print(f"âœ… åˆ†å· {os.path.basename(part_name)} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
        
        # 2. åˆå¹¶åˆ†å·
        merge_files(part_files, MERGED_ZIP_FILE)
        
        # 3. åˆ é™¤ä¸´æ—¶åˆ†å·é‡Šæ”¾ç©ºé—´
        print("ğŸ—‘ï¸ åˆ é™¤ä¸´æ—¶åˆ†å·æ–‡ä»¶...")
        for part in part_files:
            if os.path.exists(part):
                os.remove(part)
    else:
        print(f"âœ… å®Œæ•´å‹ç¼©åŒ… {MERGED_ZIP_FILE} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½å’Œåˆå¹¶")

    # --- B. è§£å‹é€»è¾‘ ---
    print(f"ğŸ“¦ æ­£åœ¨è§£å‹æ•°æ®é›†åˆ° {DATASET_DIR} ...")
    os.makedirs(DATASET_DIR, exist_ok=True)
    
    try:
        with zipfile.ZipFile(MERGED_ZIP_FILE, 'r') as zip_ref:
            # è¿™é‡Œçš„è§£å‹å¯èƒ½ä¼šæ¯”è¾ƒæ…¢ï¼Œ3GBå»ºè®®è€å¿ƒç­‰å¾…
            for member in tqdm(zip_ref.infolist(), desc="æ­£åœ¨è§£å‹"):
                zip_ref.extract(member, DATASET_DIR)
        print(f"âœ… è§£å‹å®Œæˆ")
        
        # --- C. ç›®å½•ä¿®æ­£ä¸æ¸…ç† ---
        fix_nested_dir(DATASET_DIR)

        print(f"ğŸ—‘ï¸ æ­£åœ¨åˆ é™¤åˆå¹¶åçš„å‹ç¼©åŒ…ä»¥é‡Šæ”¾ç©ºé—´: {MERGED_ZIP_FILE}")
        os.remove(MERGED_ZIP_FILE)
        print("âœ… ç©ºé—´å·²æ¸…ç†ï¼Œæ•°æ®é›†å‡†å¤‡å°±ç»ªï¼")

    except zipfile.BadZipFile:
        print("âŒ é”™è¯¯ï¼šå‹ç¼©åŒ…æŸåï¼å¯èƒ½æ˜¯ä¸‹è½½ä¸å®Œæ•´æˆ–åˆå¹¶é¡ºåºé”™è¯¯ã€‚")
        # å¦‚æœå‡ºé”™ï¼Œå°è¯•åˆ é™¤ååŒ…ï¼Œæ–¹ä¾¿é‡è¯•
        if os.path.exists(MERGED_ZIP_FILE):
            os.remove(MERGED_ZIP_FILE)

else:
    print(f"âœ… æ•°æ®é›†ç›®å½• {DATASET_DIR} å·²å­˜åœ¨ï¼Œæ— éœ€æ“ä½œ")
    # å†æ¬¡æ£€æŸ¥ç›®å½•ç»“æ„ï¼Œç¡®ä¿ä¸‡æ— ä¸€å¤±
    fix_nested_dir(DATASET_DIR)