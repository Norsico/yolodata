# 🧠 预期参数量: ~3.1 M (接近 12-13-2)
# 💻 预期 GFLOPs: ~11.0 G
# 🎯 目标: 验证 RFAConv 是否是核心涨点因子

nc: 6
scales:
  n: [0.50, 0.25, 1024]

# === Backbone (保持普通版，控制变量) ===
backbone:
  - [-1, 1, Conv, [64, 3, 2]]
  - [-1, 1, Conv, [128, 3, 2]]
  - [-1, 2, C3k2, [256, False, 0.25]]
  - [-1, 1, Conv, [256, 3, 2]]
  - [-1, 2, C3k2, [512, False, 0.25]]
  - [-1, 1, Conv, [512, 3, 2]]
  - [-1, 2, C3k2, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]]
  - [-1, 2, C3k2, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]]
  - [-1, 2, C2PSA, [1024]]

# === Head ===
head:
  - [-1, 1, DySample, [2, 'lp']]
  - [[-1, 6], 1, Concat, [1]]
  - [-1, 2, C3k2, [512, False]]

  - [-1, 1, DySample, [2, 'lp']]
  - [[-1, 4], 1, Concat, [1]]
  - [-1, 2, C3k2, [256, False]] # 16 (P3 语义流)

  # === Detail Branch (RFAConv 回归) ===
  # 1. 先用 RFAConv 从 32 扩到 128 (注意力重组)
  - [1, 1, RFAConv, [128]]      # 17
  # 2. 再用 Conv 下采样对齐尺寸
  - [-1, 1, Conv, [128, 3, 2]]  # 18

  # === 融合层 (去掉了 Gate，改用最原始的 Concat) ===
  - [[16, 18], 1, Concat, [1]]  # 19: 256(P3) + 128(Detail) = 384通道

  # === 融合后处理 ===
  # 必须加这个 Conv，把 384 降维回 256，否则后面参数量会爆炸
  # 这也模拟了 Gate 的融合输出效果
  - [-1, 1, Conv, [256, 1, 1]]  # 20: 融合特征

  # === 输出路径 ===
  - [20, 1, Conv, [256, 3, 2]]  # 21
  - [[-1, 13], 1, Concat, [1]]
  - [-1, 2, C3k2, [512, False]] # 23

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 10], 1, Concat, [1]]
  - [-1, 2, C3k2, [1024, True]] # 26

  # === Detect ===
  - [[20, 23, 26], 1, Detect, [nc]] # 注意索引变化
