import os
import shutil
import zipfile
import subprocess
import time

# === 1. è®¾ç½®ä¸‹è½½é“¾æ¥ ===
ORIGINAL_URLS = [
    'https://github.com/Norsico/yolodata/releases/download/0.2.0/SODA10M_82_6k.zip'
]

# === 2. ç­–ç•¥è°ƒæ•´ï¼šä¼˜å…ˆç”¨åŸå§‹é“¾æ¥ï¼ˆæ±‚ç¨³ï¼‰ï¼Œå…¶æ¬¡æ‰æ˜¯é•œåƒ ===
MIRRORS = [
    "",                           # <--- ç©ºå­—ç¬¦ä¸²ä»£è¡¨ä½¿ç”¨åŸå§‹ GitHub é“¾æ¥ (æœ€ç¨³)
    "https://mirror.ghproxy.com/",# <--- å¤‡ç”¨é•œåƒ1
    "https://ghproxy.net/"        # <--- å¤‡ç”¨é•œåƒ2
]

# === 3. è·¯å¾„é…ç½® ===
MERGED_ZIP_FILE = "/workspace/SODA10M_82_10k.zip"
DATASET_DIR = "/workspace/datasets/SODA10M_82_10k" 

# === 4. æ˜¯å¦å¯ç”¨åˆ†å·åˆå¹¶ ===
USE_SPLIT_FILES = False  # è®¾ç½®ä¸º False è¡¨ç¤ºä¸è¿›è¡Œåˆ†å·åˆå¹¶

def install_aria2():
    if shutil.which("aria2c") is None:
        try:
            subprocess.run(["apt-get", "update"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            subprocess.run(["apt-get", "install", "-y", "aria2"], check=True)
        except:
            pass

def download_with_aria2(url, filename, proxy_prefix):
    final_url = proxy_prefix + url
    
    # æ‰“å°å½“å‰å°è¯•çš„ç­–ç•¥
    source_name = "GitHubåŸæº" if proxy_prefix == "" else proxy_prefix
    print(f"   [Aria2] æ­£åœ¨å°è¯•: {source_name}")
    print(f"           (åœ°å€: {final_url})")
    
    cmd = [
        "aria2c", 
        "-c",                       # æ–­ç‚¹ç»­ä¼ 
        "-x", "4",                  # <--- é™åˆ° 4 çº¿ç¨‹ï¼Œé˜²æ­¢è¢«å° IP
        "-s", "4", 
        "-k", "1M", 
        "--max-tries=0",            # æ— é™é‡è¯•
        "--retry-wait=2",           # é‡è¯•ç­‰å¾…
        "--lowest-speed-limit=1K",  # åªè¦æœ‰é€Ÿåº¦å°±ä¸æ€
        "--connect-timeout=10",     # è¿æ¥è¶…æ—¶
        "--check-certificate=false",
        "--console-log-level=warn", # ä¾ç„¶ä¼šæ˜¾ç¤ºè­¦å‘Šï¼Œåˆ«æ€•
        "--summary-interval=5",     # 5ç§’åˆ·æ–°ä¸€æ¬¡è¿›åº¦
        "--dir", os.path.dirname(filename), 
        "-o", os.path.basename(filename),
        final_url
    ]
    subprocess.run(cmd, check=True)

def smart_download(url, filename):
    print(f"â¬‡ï¸ æ£€æŸ¥/ä¸‹è½½æ–‡ä»¶: {os.path.basename(filename)}")
    
    # æ­»å¾ªç¯æ¨¡å¼ï¼šåªè¦æ²¡ä¸‹å®Œï¼Œå°±ä¸€ç›´æ¢æºé‡è¯•
    attempt = 0
    while True:
        for proxy in MIRRORS:
            try:
                download_with_aria2(url, filename, proxy)
                print("âœ… æˆåŠŸå®Œæˆï¼")
                return
            except subprocess.CalledProcessError:
                attempt += 1
                print(f"âš ï¸ å½“å‰çº¿è·¯ä¸ç¨³å®šï¼Œè‡ªåŠ¨åˆ‡æ¢... (ç¬¬ {attempt} æ¬¡é‡è¯•)")
                time.sleep(2)
            except KeyboardInterrupt:
                print("\nğŸ›‘ ç”¨æˆ·æ‰‹åŠ¨åœæ­¢")
                exit()

def merge_files(part_files, output_file):
    print(f"ğŸ”— æ­£åœ¨åˆå¹¶ {len(part_files)} ä¸ªåˆ†ç‰‡...")
    with open(output_file, 'wb') as outfile:
        for part in part_files:
            print(f"   + åˆå¹¶: {os.path.basename(part)}")
            with open(part, 'rb') as infile:
                shutil.copyfileobj(infile, outfile)
    print("âœ… åˆå¹¶å®Œæˆ")

def fix_nested_dir(target_dir):
    folder_name = os.path.basename(target_dir)
    nested_path = os.path.join(target_dir, folder_name)
    if os.path.exists(nested_path) and os.path.isdir(nested_path):
        for item in os.listdir(nested_path):
            shutil.move(os.path.join(nested_path, item), os.path.join(target_dir, item))
        os.rmdir(nested_path)

# ================= ä¸»æµç¨‹ =================

if __name__ == "__main__":
    install_aria2()

    if not os.path.exists(DATASET_DIR):
        part_files = []
        
        if not os.path.exists(MERGED_ZIP_FILE):
            for index, url in enumerate(ORIGINAL_URLS):
                part_name = f"/workspace/temp_part_{index+1:03d}"
                part_files.append(part_name)
                # è¿™ä¸€æ­¥ä¼šå¡ä½ç›´åˆ°ä¸‹è½½å®Œæˆ
                smart_download(url, part_name)
            
            if USE_SPLIT_FILES and len(ORIGINAL_URLS) > 1:
                # åˆå¹¶åˆ†å·æ–‡ä»¶
                merge_files(part_files, MERGED_ZIP_FILE)
                
                # æ¸…ç†ä¸´æ—¶åˆ†ç‰‡
                for part in part_files:
                    if os.path.exists(part): os.remove(part)
                    if os.path.exists(part+".aria2"): os.remove(part+".aria2")
            
            # å¦‚æœåªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œä¸éœ€è¦åˆå¹¶åˆ†å·
            elif len(ORIGINAL_URLS) == 1:
                print(f"âš ï¸ åªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œè·³è¿‡åˆå¹¶åˆ†å·ã€‚")
                shutil.move(part_files[0], MERGED_ZIP_FILE)
            
        # è§£å‹
        print(f"ğŸ“¦ æ­£åœ¨è§£å‹...") 
        os.makedirs(DATASET_DIR, exist_ok=True)
        try:
            with zipfile.ZipFile(MERGED_ZIP_FILE, 'r') as z:
                z.extractall(DATASET_DIR)
            fix_nested_dir(DATASET_DIR)
            os.remove(MERGED_ZIP_FILE)
            print("ğŸ‰ğŸ‰ğŸ‰ æ­å–œï¼ç»ˆäºæå®šäº†ï¼")
        except Exception as e:
            print(f"âŒ è§£å‹å‡ºé”™: {e}")
    else:
        print(f"âœ… ç›®å½•å·²å­˜åœ¨: {DATASET_DIR}")
        fix_nested_dir(DATASET_DIR)
